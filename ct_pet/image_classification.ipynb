{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8xk45YOEMbB",
        "outputId": "f80f7605-c449-483b-ecc3-974bc7b891f8"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import SimpleITK as sitk\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "IMG_DEPTH = 128\n",
        "DATA_PATH = \".\\\\data\\\\\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "def write_data_file_paths():\n",
        "    with open(f\"{DATA_PATH}\\\\file_paths.csv\", \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"image\", \"mask\", \"label\"])\n",
        "        for sbj in range(100):\n",
        "            if os.path.exists(f\"{DATA_PATH}\\\\0\\\\{sbj:02}\\\\CT_partition.npy\"):\n",
        "                label = 0\n",
        "            elif os.path.exists(f\"{DATA_PATH}\\\\1\\\\{sbj:02}\\\\CT_partition.npy\"):\n",
        "                label = 1\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            writer.writerows(\n",
        "                [\n",
        "                    [\n",
        "                        f\"{label}\\\\{sbj:02}\\\\CT_partition.npy\",\n",
        "                        f\"{label}\\\\{sbj:02}\\\\CT_mask.npy\",\n",
        "                        label,\n",
        "                    ],\n",
        "                    [\n",
        "                        f\"{label}\\\\{sbj:02}\\\\PT_partition.npy\",\n",
        "                        f\"{label}\\\\{sbj:02}\\\\PT_mask.npy\",\n",
        "                        label,\n",
        "                    ],\n",
        "                ]\n",
        "            )\n",
        "\n",
        "write_data_file_paths()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y0ygXc54hHHm"
      },
      "source": [
        "### Classical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKwHAoAYAgfK"
      },
      "outputs": [],
      "source": [
        "def load_haralick_features():\n",
        "    try:\n",
        "        data = pd.read_csv(f\"haralick.csv\", index_col=0)\n",
        "        labels = data.pop(\"y\")\n",
        "        return data, labels\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found, generating...\")\n",
        "        data, labels = [], []\n",
        "\n",
        "        with open(f\"{DATA_PATH}\\\\file_paths.csv\", \"r\") as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)\n",
        "            for image_path, mask_path, label in reader:\n",
        "                image = np.load(f\"{DATA_PATH}\\\\{image_path}\")\n",
        "                mask = np.load(f\"{DATA_PATH}\\\\{mask_path}\")\n",
        "                ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtUMGnGvjljB"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE4uUrHIuV6w"
      },
      "outputs": [],
      "source": [
        "def print_metrics(y_true, y_pred, model_name) -> None:\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    print(model_name)\n",
        "    print(f\"Sensitivity: {tp / (tp + fn) * 100:.1f}%\")\n",
        "    print(f\"Specificity: {tn / (tn + fp) * 100:.1f}%\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred) * 100:.1f}%\")\n",
        "    print(f\"ROC-AUC: {roc_auc_score(y_true, y_pred) * 100:.1f}%\")\n",
        "\n",
        "    plt.imshow(cm, cmap=mpl.colormaps[\"Blues\"])\n",
        "    plt.colorbar()\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.xticks([0, 1], [\"negative\", \"positive\"])\n",
        "    plt.yticks([0, 1], [\"negative\", \"positive\"])\n",
        "    for (j, i), label in np.ndenumerate(cm):\n",
        "        color = \"darkblue\" if label < cm.max() / 2 else \"white\"\n",
        "        plt.text(i, j, label, color=color)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, labels, test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "svc_pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", MinMaxScaler()),\n",
        "        # (\"pca\", PCA(0.9)),\n",
        "        (\"svc\", SVC(kernel=\"linear\", random_state=SEED)),\n",
        "    ]\n",
        ")\n",
        "rf_pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", MinMaxScaler()),\n",
        "        # (\"pca\", PCA(0.9)),\n",
        "        (\"rf\", RandomForestClassifier(criterion=\"entropy\", random_state=SEED)),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "ElFtBgwGqen7",
        "outputId": "27779fce-c390-4773-cdaf-74f1cf9bf289"
      },
      "outputs": [],
      "source": [
        "svc_pipe.fit(X_train, y_train)\n",
        "y_pred = svc_pipe.predict(X_test)\n",
        "print_metrics(y_test, y_pred, \"Linear SVC\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kzfn2RFvDbC",
        "outputId": "5b70b773-847a-4248-f46f-8d761773420f"
      },
      "outputs": [],
      "source": [
        "rf_pipe.fit(X_train, y_train)\n",
        "y_pred = rf_pipe.predict(X_test)\n",
        "print_metrics(y_test, y_pred, \"Random Forest\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from data import CTData\n",
        "from unet import UNet, DiceLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_DEPTH = 16\n",
        "IMAGE_SIZE = 64\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_rois():\n",
        "    for sbj in range(100):\n",
        "        if sbj % 10 == 9:\n",
        "            print(f\"{sbj + 1} / 100 patients loaded\")\n",
        "\n",
        "        if os.path.exists(f\"{DATA_PATH}/CLASS1_MALIGNANT/LCp{sbj:04}_biobank\"):\n",
        "            label = \"CLASS1_MALIGNANT\"\n",
        "        elif os.path.exists(f\"{DATA_PATH}/CLASS2_BENIGN/LCp{sbj:04}_biobank\"):\n",
        "            label = \"CLASS2_BENIGN\"\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        ct_scan = sitk.ReadImage(\n",
        "            f\"{DATA_PATH}/{label}/LCp{sbj:04}_biobank/LCp{sbj:04}_CT_partition.nii\"\n",
        "        )\n",
        "        ct_scan = sitk.GetArrayFromImage(ct_scan)\n",
        "\n",
        "        mask = sitk.ReadImage(\n",
        "            f\"{DATA_PATH}/{label}/LCp{sbj:04}_biobank/LCp{sbj:04}_CT_mask.nii\"\n",
        "        )\n",
        "        mask = sitk.GetArrayFromImage(mask)\n",
        "\n",
        "        roi = np.unique(np.where(mask == 1), axis=1)\n",
        "        roi_cx, roi_cy, roi_cz = (roi.max(axis=1) + roi.min(axis=1)) // 2\n",
        "        bounding_box = mask[\n",
        "            roi_cx - IMAGE_DEPTH // 2 : roi_cx + IMAGE_DEPTH // 2,\n",
        "            roi_cy - IMAGE_SIZE // 2 : roi_cy + IMAGE_SIZE // 2,\n",
        "            roi_cz - IMAGE_SIZE // 2 : roi_cz + IMAGE_SIZE // 2,\n",
        "        ]\n",
        "        image_out = ct_scan[\n",
        "            roi_cx - IMAGE_DEPTH // 2 : roi_cx + IMAGE_DEPTH // 2,\n",
        "            roi_cy - IMAGE_SIZE // 2 : roi_cy + IMAGE_SIZE // 2,\n",
        "            roi_cz - IMAGE_SIZE // 2 : roi_cz + IMAGE_SIZE // 2,\n",
        "        ]\n",
        "\n",
        "        os.mkdir(f\"{DATA_PATH}/segmentation/{sbj:04}\")\n",
        "        np.save(f\"{DATA_PATH}/segmentation/{sbj:04}/CT_image.npy\", image_out)\n",
        "        np.save(f\"{DATA_PATH}/segmentation/{sbj:04}/CT_mask.npy\", bounding_box)\n",
        "\n",
        "save_rois()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images, masks = [], []\n",
        "for sbj in range(100):\n",
        "    try:\n",
        "        images.append(np.load(f\"{DATA_PATH}/segmentation/{sbj:04}/CT_image.npy\"))\n",
        "        masks.append(np.load(f\"{DATA_PATH}/segmentation/{sbj:04}/CT_mask.npy\"))\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        continue\n",
        "\n",
        "images = np.array(images)\n",
        "masks = np.array(masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images, test_images, train_masks, test_masks = train_test_split(\n",
        "    images, masks, test_size=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    CTData(train_images, train_masks), BATCH_SIZE, shuffle=True\n",
        ")\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    CTData(test_images, test_masks), 1, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = UNet(residual=False, cat=True).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "model.load_state_dict(torch.load(\".\\\\models\\\\conv_l1_cat_500.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def threshold(data: torch.Tensor, level: float = 0.5) -> torch.Tensor:\n",
        "    scaled = (data - data.min()) / (data.max() - data.min())\n",
        "    scaled[scaled < level] = 0\n",
        "    scaled[scaled >= level] = 1\n",
        "    return scaled\n",
        "\n",
        "\n",
        "def pixel_accuracy(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sum(pred == true) / np.prod(pred.shape)\n",
        "\n",
        "\n",
        "def iou(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
        "    intersection = torch.logical_and(true, pred)\n",
        "    union = torch.logical_or(true, pred)\n",
        "    return torch.sum(intersection) / torch.sum(union)\n",
        "\n",
        "\n",
        "def dice_coeff(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
        "    intersection = torch.logical_and(true, pred)\n",
        "    return 2 * torch.sum(intersection) / (torch.sum(true) + torch.sum(pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pixel_loss, iou_loss, dice_loss = [], [], []\n",
        "\n",
        "for epochs in range(EPOCHS):\n",
        "    print(f\"Epoch {epochs + 1} / {EPOCHS}\")\n",
        "    model.train()\n",
        "    for image, mask in train_dataloader:\n",
        "        image = image.to(device)\n",
        "        mask = mask.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = threshold(model(image))\n",
        "        loss = iou(pred, mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    epoch_pixel_loss, epoch_iou_loss, epoch_dice_loss = [], [], []\n",
        "    for image, mask in test_dataloader:\n",
        "        image = image.to(device)\n",
        "        mask = mask.to(device)\n",
        "        pred = threshold(model(image))\n",
        "\n",
        "        pixel = pixel_accuracy(pred, mask)\n",
        "        jaccard = iou(pred, mask)\n",
        "        dice = dice_coeff(pred, mask)\n",
        "        \n",
        "        print(f\"Pixel accuracy: {pixel_accuracy(pred, mask):.4f}\")\n",
        "        print(f\"IOU (Jaccard): {iou(pred, mask):.4f}\")\n",
        "        print(f\"Dice coefficient (F1-score): {dice_coeff(pred, mask):.4f}\")\n",
        "\n",
        "        epoch_pixel_loss.append(pixel)\n",
        "        epoch_iou_loss.append(jaccard)\n",
        "        epoch_dice_loss.append(dice)\n",
        "    \n",
        "    pixel_loss.append(np.mean(epoch_pixel_loss))\n",
        "    iou_loss.append(np.mean(epoch_iou_loss))\n",
        "    dice_loss.append(np.mean(epoch_dice_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iter_data = iter(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image, mask = next(iter_data)\n",
        "pred = threshold(model(image))\n",
        "\n",
        "print(f\"Pixel accuracy: {pixel_accuracy(pred, mask):.4f}\")\n",
        "print(f\"IOU (Jaccard): {iou(pred, mask):.4f}\")\n",
        "print(f\"Dice coefficient (F1-score): {dice_coeff(pred, mask):.4f}\")\n",
        "\n",
        "image = image.cpu().detach().numpy()\n",
        "pred = pred.cpu().detach().numpy()\n",
        "mask = mask.cpu().detach().numpy()\n",
        "\n",
        "fig, ax = plt.subplots(4, 12)\n",
        "for slc in range(16):\n",
        "    r, c = divmod(slc, 4)\n",
        "\n",
        "    ax[r, c].imshow(image[0, 0, slc, :, :])\n",
        "    ax[r, c + 4].imshow(pred[0, 0, slc, :, :])\n",
        "    ax[r, c + 8].imshow(mask[0, 0, slc, :, :])\n",
        "\n",
        "    ax[r, c].axis(\"off\")\n",
        "    ax[r, c + 4].axis(\"off\")\n",
        "    ax[r, c + 8].axis(\"off\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
