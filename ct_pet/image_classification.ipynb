{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8xk45YOEMbB",
        "outputId": "f80f7605-c449-483b-ecc3-974bc7b891f8"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "IMG_DEPTH = 128\n",
        "DATA_PATH = r\".\\data\"\n",
        "MODEL_PATH = r\".\\models\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y0ygXc54hHHm"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_data_file_paths():\n",
        "    with open(rf\"{DATA_PATH}\\file_paths.csv\", \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"image\", \"mask\", \"label\"])\n",
        "        for sbj in range(100):\n",
        "            if os.path.exists(rf\"{DATA_PATH}\\0\\{sbj:02}\"):\n",
        "                label = 0\n",
        "            elif os.path.exists(rf\"{DATA_PATH}\\1\\{sbj:02}\"):\n",
        "                label = 1\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            for scan in (\"CT\", \"PT\"):\n",
        "                writer.writerow(\n",
        "                    [\n",
        "                        rf\"{label}\\{sbj:02}\\{scan}_partition.npy\",\n",
        "                        rf\"{label}\\{sbj:02}\\{scan}_mask.npy\",\n",
        "                        label,\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "\n",
        "write_data_file_paths()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKwHAoAYAgfK"
      },
      "outputs": [],
      "source": [
        "def load_haralick_features():\n",
        "    try:\n",
        "        data = pd.read_csv(rf\"{DATA_PATH}\\haralick.csv\", index_col=0)\n",
        "        labels = data.pop(\"y\")\n",
        "        return data, labels\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found, generating...\")\n",
        "        data, labels = [], []\n",
        "\n",
        "        with open(rf\"{DATA_PATH}\\file_paths.csv\", \"r\") as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)\n",
        "            for image_path, mask_path, _ in reader:\n",
        "                image = np.load(rf\"{DATA_PATH}\\{image_path}\")\n",
        "                mask = np.load(rf\"{DATA_PATH}\\{mask_path}\")\n",
        "                ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtUMGnGvjljB"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE4uUrHIuV6w"
      },
      "outputs": [],
      "source": [
        "def print_metrics(y_true, y_pred, model_name) -> None:\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    print(model_name)\n",
        "    print(f\"Sensitivity: {tp / (tp + fn) * 100:.1f}%\")\n",
        "    print(f\"Specificity: {tn / (tn + fp) * 100:.1f}%\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred) * 100:.1f}%\")\n",
        "    print(f\"ROC-AUC: {roc_auc_score(y_true, y_pred) * 100:.1f}%\")\n",
        "\n",
        "    plt.imshow(cm, cmap=mpl.colormaps[\"Blues\"])\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"{model_name} Confusion matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.xticks([0, 1], [\"negative\", \"positive\"])\n",
        "    plt.yticks([0, 1], [\"negative\", \"positive\"])\n",
        "    for (j, i), label in np.ndenumerate(cm):\n",
        "        color = \"darkblue\" if label < cm.max() / 2 else \"white\"\n",
        "        plt.text(i, j, label, color=color)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    *load_haralick_features(), test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "svc_pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", MinMaxScaler()),\n",
        "        # (\"pca\", PCA(0.9)),\n",
        "        (\"svc\", SVC(kernel=\"linear\", random_state=SEED)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "rf_pipe = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", MinMaxScaler()),\n",
        "        # (\"pca\", PCA(0.9)),\n",
        "        (\"rf\", RandomForestClassifier(criterion=\"entropy\", random_state=SEED)),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "ElFtBgwGqen7",
        "outputId": "27779fce-c390-4773-cdaf-74f1cf9bf289"
      },
      "outputs": [],
      "source": [
        "svc_pipe.fit(X_train, y_train)\n",
        "y_pred = svc_pipe.predict(X_test)\n",
        "print_metrics(y_test, y_pred, \"Linear SVC\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kzfn2RFvDbC",
        "outputId": "5b70b773-847a-4248-f46f-8d761773420f"
      },
      "outputs": [],
      "source": [
        "rf_pipe.fit(X_train, y_train)\n",
        "y_pred = rf_pipe.predict(X_test)\n",
        "print_metrics(y_test, y_pred, \"Random Forest\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from data import CTData\n",
        "from unet import UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_DEPTH = 16\n",
        "IMAGE_SIZE = 64\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_rois():\n",
        "    for sbj in range(100):\n",
        "        if sbj % 10 == 9:\n",
        "            print(f\"{sbj + 1} / 100 patients segmented\")\n",
        "\n",
        "        if os.path.exists(rf\"{DATA_PATH}\\0\\{sbj:02}\"):\n",
        "            label = 0\n",
        "        elif os.path.exists(rf\"{DATA_PATH}\\1\\{sbj:02}\"):\n",
        "            label = 1\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        ct_scan = np.load(rf\"{DATA_PATH}\\{label}\\{sbj:02}\\CT_partition.npy\")\n",
        "        mask = np.load(rf\"{DATA_PATH}\\{label}\\{sbj:02}\\CT_mask.npy\")\n",
        "\n",
        "        roi = np.unique(np.where(mask == 1), axis=1)\n",
        "        roi_cx, roi_cy, roi_cz = (roi.max(axis=1) + roi.min(axis=1)) // 2\n",
        "        bounding_box = mask[\n",
        "            roi_cx - IMAGE_DEPTH // 2 : roi_cx + IMAGE_DEPTH // 2,\n",
        "            roi_cy - IMAGE_SIZE // 2 : roi_cy + IMAGE_SIZE // 2,\n",
        "            roi_cz - IMAGE_SIZE // 2 : roi_cz + IMAGE_SIZE // 2,\n",
        "        ]\n",
        "        image_out = ct_scan[\n",
        "            roi_cx - IMAGE_DEPTH // 2 : roi_cx + IMAGE_DEPTH // 2,\n",
        "            roi_cy - IMAGE_SIZE // 2 : roi_cy + IMAGE_SIZE // 2,\n",
        "            roi_cz - IMAGE_SIZE // 2 : roi_cz + IMAGE_SIZE // 2,\n",
        "        ]\n",
        "\n",
        "        # os.mkdir(rf\"{DATA_PATH}\\segmentation\\{sbj:02}\")\n",
        "        np.save(rf\"{DATA_PATH}\\segmentation\\{sbj:02}\\CT_image.npy\", image_out)\n",
        "        np.save(rf\"{DATA_PATH}\\segmentation\\{sbj:02}\\CT_mask.npy\", bounding_box)\n",
        "\n",
        "\n",
        "save_rois()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images, masks = [], []\n",
        "for sbj in range(100):\n",
        "    try:\n",
        "        images.append(np.load(f\"{DATA_PATH}/rois/{sbj:02}/CT_image.npy\"))\n",
        "        masks.append(np.load(f\"{DATA_PATH}/rois/{sbj:02}/CT_mask.npy\"))\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        continue\n",
        "\n",
        "images = np.array(images)\n",
        "masks = np.array(masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images, test_images, train_masks, test_masks = train_test_split(\n",
        "    images, masks, test_size=0.2, random_state=SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    CTData(train_images, train_masks), BATCH_SIZE, shuffle=True\n",
        ")\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    CTData(test_images, test_masks), 1, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def threshold(data: torch.Tensor, level: float = 0.5) -> torch.Tensor:\n",
        "    scaled = (data - data.min()) / (data.max() - data.min())\n",
        "    scaled[scaled < level] = 0\n",
        "    scaled[scaled >= level] = 1\n",
        "    return scaled\n",
        "\n",
        "\n",
        "def pixel_accuracy(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sum(pred == true) / np.prod(pred.shape)\n",
        "\n",
        "\n",
        "def iou(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
        "    intersection = torch.logical_and(true, pred)\n",
        "    union = torch.logical_or(true, pred)\n",
        "    return torch.sum(intersection) / torch.sum(union)\n",
        "\n",
        "\n",
        "def dice_coeff(pred: torch.Tensor, true: torch.Tensor) -> torch.Tensor:\n",
        "    intersection = torch.logical_and(true, pred)\n",
        "    return 2 * torch.sum(intersection) / (torch.sum(true) + torch.sum(pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = UNet(residual=False, cat=False).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_fn = torch.nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pixel_loss, iou_loss, dice_loss = [], [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    for image, mask in train_dataloader:\n",
        "        image = image.to(device)\n",
        "        mask = mask.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        # pred = threshold(model(image))\n",
        "        pred = model(image)\n",
        "        loss = loss_fn(pred, mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 20 == 19:\n",
        "        # model.eval()\n",
        "        # epoch_pixel_loss, epoch_iou_loss, epoch_dice_loss = [], [], []\n",
        "        # for image, mask in test_dataloader:\n",
        "        #     image = image.to(device)\n",
        "        #     mask = mask.to(device)\n",
        "        #     pred = threshold(model(image))\n",
        "\n",
        "        #     pixel = pixel_accuracy(pred, mask)\n",
        "        #     jaccard = iou(pred, mask)\n",
        "        #     dice = dice_coeff(pred, mask)\n",
        "\n",
        "        #     epoch_pixel_loss.append(pixel)\n",
        "        #     epoch_iou_loss.append(jaccard)\n",
        "        #     epoch_dice_loss.append(dice)\n",
        "\n",
        "        # mean_pixel_loss = np.mean(epoch_pixel_loss)\n",
        "        # mean_iou_loss = np.mean(epoch_iou_loss)\n",
        "        # mean_dice_loss = np.mean(epoch_dice_loss)\n",
        "        \n",
        "        # pixel_loss.append(mean_pixel_loss)\n",
        "        # iou_loss.append(mean_iou_loss)\n",
        "        # dice_loss.append(mean_dice_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} / {EPOCHS} metrics:\")\n",
        "        # print(f\"PA {mean_pixel_loss:.2f} | IoU {mean_iou_loss:.2f} | Dice {mean_dice_loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), rf\"{MODEL_PATH}\\ct_l1_1300.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.cpu()\n",
        "iter_data = iter(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image, mask = next(iter_data)\n",
        "pred = threshold(model(image))\n",
        "\n",
        "print(f\"Pixel accuracy: {pixel_accuracy(pred, mask):.4f}\")\n",
        "print(f\"IOU (Jaccard): {iou(pred, mask):.4f}\")\n",
        "print(f\"Dice coefficient (F1-score): {dice_coeff(pred, mask):.4f}\")\n",
        "\n",
        "image = image.cpu().detach().numpy()\n",
        "pred = pred.cpu().detach().numpy()\n",
        "mask = mask.cpu().detach().numpy()\n",
        "\n",
        "fig, ax = plt.subplots(4, 12)\n",
        "for slc in range(16):\n",
        "    r, c = divmod(slc, 4)\n",
        "\n",
        "    ax[r, c].imshow(image[0, 0, slc, :, :])\n",
        "    ax[r, c + 4].imshow(pred[0, 0, slc, :, :])\n",
        "    ax[r, c + 8].imshow(mask[0, 0, slc, :, :])\n",
        "\n",
        "    ax[r, c].axis(\"off\")\n",
        "    ax[r, c + 4].axis(\"off\")\n",
        "    ax[r, c + 8].axis(\"off\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import radiomics\n",
        "import SimpleITK as sitk\n",
        "from radiomics import featureextractor\n",
        "\n",
        "radiomics.setVerbosity(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_haralick_features(image: np.ndarray, mask: np.ndarray) -> np.ndarray:\n",
        "    img = sitk.GetImageFromArray(image)\n",
        "    msk = sitk.GetImageFromArray(mask)\n",
        "    \n",
        "    extractor = featureextractor.RadiomicsFeatureExtractor()\n",
        "    extractor.disableAllFeatures()\n",
        "    extractor.enableFeatureClassByName(\"glcm\")\n",
        "    result = extractor.execute(img, msk)\n",
        "    return np.array([value for key, value in result.items() if \"glcm\" in key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = UNet(residual=False, cat=True)\n",
        "model.load_state_dict(torch.load(rf\"{MODEL_PATH}\\ct_l1_800.pt\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = []\n",
        "for image, _ in train_dataloader:\n",
        "    mask = threshold(model(image)).cpu().detach().numpy()\n",
        "    features.append(get_haralick_features(image, mask))\n",
        "X_train = np.array(features)\n",
        "\n",
        "features = []\n",
        "for image, _ in test_dataloader:\n",
        "    mask = threshold(model(image)).cpu().detach().numpy()\n",
        "    features.append(get_haralick_features(image, mask))\n",
        "X_test = np.array(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "svc_pipe.fit(X_train, y_train)\n",
        "y_pred = svc_pipe.predict(X_test)\n",
        "print_metrics(y_test, y_pred, \"Linear SVC\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(svc_pipe, rf\"{MODEL_PATH}\\svc.joblib\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
